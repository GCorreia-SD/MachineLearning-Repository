{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"left\" style=\"font-weight: bold; font-family: Computer Modern; font-size: 24px; text-align: left; line-height: 1.5;\">\n",
    "    Universidade Federal da Bahia\n",
    "    <br>\n",
    "    Departamento de Engenharia Elétrica e da Computação\n",
    "    <br>\n",
    "    Disciplina: ENGG67 - Introdução ao Aprendizado de Máquina\n",
    "    <br>\n",
    "    Docente: Antônio Fernandes\n",
    "    <br>\n",
    "    Discentes: Márcio Barros e Gabriel Correia\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"left\" style=\"font-weight: bold; font-family: Computer Modern;font-size: 32px;text-align: left;\">\n",
    "    Avaliação 03: Abordagem usando MLPs\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O trabalho aqui apresentado visa construir uma Máquina de Aprendizado (através de uma abordagem usando MLP) que se torne uma verificadora universal para dados sobre exames provenientes da Mamografia. Sabemos mais do que nunca como o câncer de mama é um dos que mais matas mulheres (ou as fazem passar por dolorosos processos), logo, a ideia desse programa surgiu com o intuito de deixar alguma forma de ajuda, mesmo que indiretamente, para a sociedade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 align=\"left\" style=\"font-weight: bold; font-family: Computer Modern;font-size: 22px;text-align: left;\">\n",
    "    1)  Escolha uma tarefa de classificação ou regressão que possa ser abordada utilizando MLPs. Selecione um banco de dados adequado (sugestões em https://archive.ics.uci.edu/). Projete e treine uma rede MLP de duas camadas para resolver a tarefa pretendida. Utilize o método de validação cruzada k−fold para avaliar o treinamento do modelo. \n",
    "</h2> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados Obtidos no Programa: \n",
      "\n",
      "Tabela Inicial (Primeiros 5 e Últimos 5 valores):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET_COLUMN</th>\n",
       "      <th>radius_1</th>\n",
       "      <th>texture_1</th>\n",
       "      <th>perimeter_1</th>\n",
       "      <th>area_1</th>\n",
       "      <th>smoothness_1</th>\n",
       "      <th>compactness_1</th>\n",
       "      <th>concavity_1</th>\n",
       "      <th>concave_points_1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_3</th>\n",
       "      <th>texture_3</th>\n",
       "      <th>perimeter_3</th>\n",
       "      <th>area_3</th>\n",
       "      <th>smoothness_3</th>\n",
       "      <th>compactness_3</th>\n",
       "      <th>concavity_3</th>\n",
       "      <th>concave_points_3</th>\n",
       "      <th>symmetry_3</th>\n",
       "      <th>fractal_dimension_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302.0</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517.0</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903.0</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301.0</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402.0</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424.0</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682.0</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954.0</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241.0</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751.0</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID TARGET_COLUMN  radius_1  texture_1  perimeter_1  area_1  \\\n",
       "0      842302.0             M     17.99      10.38       122.80  1001.0   \n",
       "1      842517.0             M     20.57      17.77       132.90  1326.0   \n",
       "2    84300903.0             M     19.69      21.25       130.00  1203.0   \n",
       "3    84348301.0             M     11.42      20.38        77.58   386.1   \n",
       "4    84358402.0             M     20.29      14.34       135.10  1297.0   \n",
       "..          ...           ...       ...        ...          ...     ...   \n",
       "564    926424.0             M     21.56      22.39       142.00  1479.0   \n",
       "565    926682.0             M     20.13      28.25       131.20  1261.0   \n",
       "566    926954.0             M     16.60      28.08       108.30   858.1   \n",
       "567    927241.0             M     20.60      29.33       140.10  1265.0   \n",
       "568     92751.0             B      7.76      24.54        47.92   181.0   \n",
       "\n",
       "     smoothness_1  compactness_1  concavity_1  concave_points_1  ...  \\\n",
       "0         0.11840        0.27760      0.30010           0.14710  ...   \n",
       "1         0.08474        0.07864      0.08690           0.07017  ...   \n",
       "2         0.10960        0.15990      0.19740           0.12790  ...   \n",
       "3         0.14250        0.28390      0.24140           0.10520  ...   \n",
       "4         0.10030        0.13280      0.19800           0.10430  ...   \n",
       "..            ...            ...          ...               ...  ...   \n",
       "564       0.11100        0.11590      0.24390           0.13890  ...   \n",
       "565       0.09780        0.10340      0.14400           0.09791  ...   \n",
       "566       0.08455        0.10230      0.09251           0.05302  ...   \n",
       "567       0.11780        0.27700      0.35140           0.15200  ...   \n",
       "568       0.05263        0.04362      0.00000           0.00000  ...   \n",
       "\n",
       "     radius_3  texture_3  perimeter_3  area_3  smoothness_3  compactness_3  \\\n",
       "0      25.380      17.33       184.60  2019.0       0.16220        0.66560   \n",
       "1      24.990      23.41       158.80  1956.0       0.12380        0.18660   \n",
       "2      23.570      25.53       152.50  1709.0       0.14440        0.42450   \n",
       "3      14.910      26.50        98.87   567.7       0.20980        0.86630   \n",
       "4      22.540      16.67       152.20  1575.0       0.13740        0.20500   \n",
       "..        ...        ...          ...     ...           ...            ...   \n",
       "564    25.450      26.40       166.10  2027.0       0.14100        0.21130   \n",
       "565    23.690      38.25       155.00  1731.0       0.11660        0.19220   \n",
       "566    18.980      34.12       126.70  1124.0       0.11390        0.30940   \n",
       "567    25.740      39.42       184.60  1821.0       0.16500        0.86810   \n",
       "568     9.456      30.37        59.16   268.6       0.08996        0.06444   \n",
       "\n",
       "     concavity_3  concave_points_3  symmetry_3  fractal_dimension_3  \n",
       "0         0.7119            0.2654      0.4601              0.11890  \n",
       "1         0.2416            0.1860      0.2750              0.08902  \n",
       "2         0.4504            0.2430      0.3613              0.08758  \n",
       "3         0.6869            0.2575      0.6638              0.17300  \n",
       "4         0.4000            0.1625      0.2364              0.07678  \n",
       "..           ...               ...         ...                  ...  \n",
       "564       0.4107            0.2216      0.2060              0.07115  \n",
       "565       0.3215            0.1628      0.2572              0.06637  \n",
       "566       0.3403            0.1418      0.2218              0.07820  \n",
       "567       0.9387            0.2650      0.4087              0.12400  \n",
       "568       0.0000            0.0000      0.2871              0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo Estatístico dos Dados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30371831.432337</td>\n",
       "      <td>125020585.612224</td>\n",
       "      <td>8670.0</td>\n",
       "      <td>869218.0</td>\n",
       "      <td>906024.0</td>\n",
       "      <td>8813129.0</td>\n",
       "      <td>911320502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TARGET_COLUMN</td>\n",
       "      <td>569</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>radius_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981</td>\n",
       "      <td>11.7</td>\n",
       "      <td>13.37</td>\n",
       "      <td>15.78</td>\n",
       "      <td>28.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>texture_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.71</td>\n",
       "      <td>16.17</td>\n",
       "      <td>18.84</td>\n",
       "      <td>21.8</td>\n",
       "      <td>39.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perimeter_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.79</td>\n",
       "      <td>75.17</td>\n",
       "      <td>86.24</td>\n",
       "      <td>104.1</td>\n",
       "      <td>188.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>area_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.5</td>\n",
       "      <td>420.3</td>\n",
       "      <td>551.1</td>\n",
       "      <td>782.7</td>\n",
       "      <td>2501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>smoothness_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09636</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.08637</td>\n",
       "      <td>0.09587</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>compactness_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.09263</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.3454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>concavity_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.07972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.4268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>concave_points_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>symmetry_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fractal_dimension_1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.00706</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.06612</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>radius_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>2.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>texture_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>1.108</td>\n",
       "      <td>1.474</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>perimeter_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757</td>\n",
       "      <td>1.606</td>\n",
       "      <td>2.287</td>\n",
       "      <td>3.357</td>\n",
       "      <td>21.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>area_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802</td>\n",
       "      <td>17.85</td>\n",
       "      <td>24.53</td>\n",
       "      <td>45.19</td>\n",
       "      <td>542.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>smoothness_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.00638</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>compactness_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.02045</td>\n",
       "      <td>0.03245</td>\n",
       "      <td>0.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>concavity_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>0.02589</td>\n",
       "      <td>0.04205</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>concave_points_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.00617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.01093</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>symmetry_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.01516</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02348</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fractal_dimension_2</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>radius_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.26919</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.93</td>\n",
       "      <td>13.01</td>\n",
       "      <td>14.97</td>\n",
       "      <td>18.79</td>\n",
       "      <td>36.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>texture_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.02</td>\n",
       "      <td>21.08</td>\n",
       "      <td>25.41</td>\n",
       "      <td>29.72</td>\n",
       "      <td>49.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>perimeter_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.41</td>\n",
       "      <td>84.11</td>\n",
       "      <td>97.66</td>\n",
       "      <td>125.4</td>\n",
       "      <td>251.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>area_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.2</td>\n",
       "      <td>515.3</td>\n",
       "      <td>686.5</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>4254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>smoothness_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.2226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>compactness_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3391</td>\n",
       "      <td>1.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>concavity_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.3829</td>\n",
       "      <td>1.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>concave_points_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.09993</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>symmetry_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.6638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fractal_dimension_3</td>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.05504</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>0.08004</td>\n",
       "      <td>0.09208</td>\n",
       "      <td>0.2075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  count unique  top freq             mean  \\\n",
       "0                    ID  569.0    NaN  NaN  NaN  30371831.432337   \n",
       "1         TARGET_COLUMN    569      2    B  357              NaN   \n",
       "2              radius_1  569.0    NaN  NaN  NaN        14.127292   \n",
       "3             texture_1  569.0    NaN  NaN  NaN        19.289649   \n",
       "4           perimeter_1  569.0    NaN  NaN  NaN        91.969033   \n",
       "5                area_1  569.0    NaN  NaN  NaN       654.889104   \n",
       "6          smoothness_1  569.0    NaN  NaN  NaN          0.09636   \n",
       "7         compactness_1  569.0    NaN  NaN  NaN         0.104341   \n",
       "8           concavity_1  569.0    NaN  NaN  NaN         0.088799   \n",
       "9      concave_points_1  569.0    NaN  NaN  NaN         0.048919   \n",
       "10           symmetry_1  569.0    NaN  NaN  NaN         0.181162   \n",
       "11  fractal_dimension_1  569.0    NaN  NaN  NaN         0.062798   \n",
       "12             radius_2  569.0    NaN  NaN  NaN         0.405172   \n",
       "13            texture_2  569.0    NaN  NaN  NaN         1.216853   \n",
       "14          perimeter_2  569.0    NaN  NaN  NaN         2.866059   \n",
       "15               area_2  569.0    NaN  NaN  NaN        40.337079   \n",
       "16         smoothness_2  569.0    NaN  NaN  NaN         0.007041   \n",
       "17        compactness_2  569.0    NaN  NaN  NaN         0.025478   \n",
       "18          concavity_2  569.0    NaN  NaN  NaN         0.031894   \n",
       "19     concave_points_2  569.0    NaN  NaN  NaN         0.011796   \n",
       "20           symmetry_2  569.0    NaN  NaN  NaN         0.020542   \n",
       "21  fractal_dimension_2  569.0    NaN  NaN  NaN         0.003795   \n",
       "22             radius_3  569.0    NaN  NaN  NaN         16.26919   \n",
       "23            texture_3  569.0    NaN  NaN  NaN        25.677223   \n",
       "24          perimeter_3  569.0    NaN  NaN  NaN       107.261213   \n",
       "25               area_3  569.0    NaN  NaN  NaN       880.583128   \n",
       "26         smoothness_3  569.0    NaN  NaN  NaN         0.132369   \n",
       "27        compactness_3  569.0    NaN  NaN  NaN         0.254265   \n",
       "28          concavity_3  569.0    NaN  NaN  NaN         0.272188   \n",
       "29     concave_points_3  569.0    NaN  NaN  NaN         0.114606   \n",
       "30           symmetry_3  569.0    NaN  NaN  NaN         0.290076   \n",
       "31  fractal_dimension_3  569.0    NaN  NaN  NaN         0.083946   \n",
       "\n",
       "                 std       min       25%       50%        75%          max  \n",
       "0   125020585.612224    8670.0  869218.0  906024.0  8813129.0  911320502.0  \n",
       "1                NaN       NaN       NaN       NaN        NaN          NaN  \n",
       "2           3.524049     6.981      11.7     13.37      15.78        28.11  \n",
       "3           4.301036      9.71     16.17     18.84       21.8        39.28  \n",
       "4          24.298981     43.79     75.17     86.24      104.1        188.5  \n",
       "5         351.914129     143.5     420.3     551.1      782.7       2501.0  \n",
       "6           0.014064   0.05263   0.08637   0.09587     0.1053       0.1634  \n",
       "7           0.052813   0.01938   0.06492   0.09263     0.1304       0.3454  \n",
       "8            0.07972       0.0   0.02956   0.06154     0.1307       0.4268  \n",
       "9           0.038803       0.0   0.02031    0.0335      0.074       0.2012  \n",
       "10          0.027414     0.106    0.1619    0.1792     0.1957        0.304  \n",
       "11           0.00706   0.04996    0.0577   0.06154    0.06612      0.09744  \n",
       "12          0.277313    0.1115    0.2324    0.3242     0.4789        2.873  \n",
       "13          0.551648    0.3602    0.8339     1.108      1.474        4.885  \n",
       "14          2.021855     0.757     1.606     2.287      3.357        21.98  \n",
       "15         45.491006     6.802     17.85     24.53      45.19        542.2  \n",
       "16          0.003003  0.001713  0.005169   0.00638   0.008146      0.03113  \n",
       "17          0.017908  0.002252   0.01308   0.02045    0.03245       0.1354  \n",
       "18          0.030186       0.0   0.01509   0.02589    0.04205        0.396  \n",
       "19           0.00617       0.0  0.007638   0.01093    0.01471      0.05279  \n",
       "20          0.008266  0.007882   0.01516   0.01873    0.02348      0.07895  \n",
       "21          0.002646  0.000895  0.002248  0.003187   0.004558      0.02984  \n",
       "22          4.833242      7.93     13.01     14.97      18.79        36.04  \n",
       "23          6.146258     12.02     21.08     25.41      29.72        49.54  \n",
       "24         33.602542     50.41     84.11     97.66      125.4        251.2  \n",
       "25        569.356993     185.2     515.3     686.5     1084.0       4254.0  \n",
       "26          0.022832   0.07117    0.1166    0.1313      0.146       0.2226  \n",
       "27          0.157336   0.02729    0.1472    0.2119     0.3391        1.058  \n",
       "28          0.208624       0.0    0.1145    0.2267     0.3829        1.252  \n",
       "29          0.065732       0.0   0.06493   0.09993     0.1614        0.291  \n",
       "30          0.061867    0.1565    0.2504    0.2822     0.3179       0.6638  \n",
       "31          0.018061   0.05504   0.07146   0.08004    0.09208       0.2075  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há dados faltantes no conjunto de dados.\n",
      "Não há dados faltantes no conjunto de dados.\n",
      "\n",
      "OBSERVAÇÃO: Esses Dados NÃO Estão Normalizados\n",
      "\n",
      "Análise do Treinamento da Rede MLP\n",
      "Fold 1 - Acurácia: 0.9649, Precisão: 0.9652, Revocação: 0.9649, F1-score: 0.9647\n",
      "Fold 2 - Acurácia: 0.9386, Precisão: 0.9441, Revocação: 0.9386, F1-score: 0.9373\n",
      "Fold 3 - Acurácia: 0.9737, Precisão: 0.9747, Revocação: 0.9737, F1-score: 0.9735\n",
      "Fold 4 - Acurácia: 0.9825, Precisão: 0.9833, Revocação: 0.9825, F1-score: 0.9825\n",
      "Fold 5 - Acurácia: 0.9912, Precisão: 0.9913, Revocação: 0.9912, F1-score: 0.9911\n",
      "\n",
      "Acurácia Média (Accuracy): 0.9702\n",
      "Precisão Média (Precision): 0.9717\n",
      "Revocação Média (Recall): 0.9702\n",
      "F1-score Média (P*R/(P+R)): 0.9698\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\GCorr\\OneDrive\\02 - ESTUDO\\01 - UFBA\\TÓPICOS ESPECIAIS EM ENG. COMPUTAÇÃO I\\TRABALHOS DEFINITIVOS\\ATV3-GCorreia_MBarros.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=355'>356</a>\u001b[0m model_params_all_folds \u001b[39m=\u001b[39m train_mlp_model(X_processed, y_processed)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=357'>358</a>\u001b[0m \u001b[39m# Salvar o modelo treinado em um arquivo\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=358'>359</a>\u001b[0m \u001b[39m#import joblib\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=359'>360</a>\u001b[0m \u001b[39m#joblib.dump(model_params_all_folds, 'mlp_model.joblib')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=363'>364</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=364'>365</a>\u001b[0m \u001b[39m# Exibir os parâmetros e informações das camadas para todos os folds\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=365'>366</a>\u001b[0m \u001b[39mfor\u001b[39;00m fold, model_params \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(model_params_all_folds, num_folds):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=366'>367</a>\u001b[0m     model \u001b[39m=\u001b[39m model_params[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/GCorr/OneDrive/02%20-%20ESTUDO/01%20-%20UFBA/T%C3%93PICOS%20ESPECIAIS%20EM%20ENG.%20COMPUTA%C3%87%C3%83O%20I/TRABALHOS%20DEFINITIVOS/ATV3-GCorreia_MBarros.ipynb#W4sZmlsZQ%3D%3D?line=367'>368</a>\u001b[0m     df_parameters \u001b[39m=\u001b[39m get_mlp_parameters(model_params[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_folds' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import learning_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.close('all')\n",
    "print('Resultados Obtidos no Programa: ')\n",
    "\n",
    "# Configurações Globais do Script (Podemos Alterar para Analisar algum Comportamento em Específico)\n",
    "UCI_DATASET_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "DATA_FILENAME = \"wdbc.data\"\n",
    "TARGET_COLUMN = \"Diagnosis\"\n",
    "NUM_HIDDEN_LAYERS = (20,)\n",
    "MAX_ITER = 100\n",
    "RANDOM_STATE = 42\n",
    "NUM_FOLDS = 5\n",
    "NORMALIZATION_FLAG = 0  # 1 for ON, 0 for OFF\n",
    "NUM_K = 5\n",
    "\n",
    "# Suprimir os avisos de convergência do MLPClassifier\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def download_and_load_data():\n",
    "    # Download do conjunto de dados de câncer de mama da UCI\n",
    "    url = UCI_DATASET_URL\n",
    "    response = requests.get(url, verify=True)\n",
    "\n",
    "    # Salvar o arquivo no sistema local\n",
    "    with open(DATA_FILENAME, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Ler os dados do arquivo CSV baixado\n",
    "    column_names = [\"ID\", \"TARGET_COLUMN\"] + [f\"{feature}_{i}\" for i in range(1, 4) for feature in [\"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\", \"concavity\", \"concave_points\", \"symmetry\", \"fractal_dimension\"]]\n",
    "    cancer_data = pd.read_csv(\"DATA_FILENAME\", header=None, names=column_names)\n",
    "\n",
    "    return cancer_data\n",
    "\n",
    "def display_initial_table(cancer_data):\n",
    "    # Exibir a tabela inicial\n",
    "    print(\"\\nTabela Inicial (Primeiros 5 e Últimos 5 valores):\")\n",
    "    display(pd.concat([cancer_data.head(), pd.DataFrame([\"...\"] * (len(cancer_data) - 10)).set_index([0]), cancer_data.tail()]))\n",
    "\n",
    "def display_data_summary(cancer_data):\n",
    "    # Resumo Estatístico dos Dados\n",
    "    print(\"\\nResumo Estatístico dos Dados:\")\n",
    "    summary_table = cancer_data.describe(include='all').transpose().reset_index()\n",
    "    summary_table = summary_table.rename(columns={'index': 'Feature'})\n",
    "    display(summary_table)\n",
    "\n",
    "def visualize_class_distribution(cancer_data):\n",
    "    # Visualização da Distribuição das Classes\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    diagnosis_counts = cancer_data['TARGET_COLUMN'].value_counts()\n",
    "    diagnosis_counts.plot(kind='bar', color=['navy', 'red'])\n",
    "    plt.title('Distribuição dos Diagnósticos')\n",
    "    plt.xlabel('Diagnóstico')\n",
    "    plt.ylabel('Contagem')\n",
    "    plt.xticks(rotation=0, horizontalalignment=\"center\")  # Ajustar a orientação do texto no eixo X\n",
    "    plt.show()\n",
    "\n",
    "def visualize_column_distribution(cancer_data):\n",
    "    # Obter número de colunas\n",
    "    num_cols = 3\n",
    "\n",
    "    # Calcular número total de subplots necessários\n",
    "    num_features = len(cancer_data.columns[2:])\n",
    "    num_rows = (num_features + num_cols - 1) // num_cols\n",
    "\n",
    "    # Criar a grade de subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "\n",
    "    # Ajustar o espaçamento entre os subplots\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "\n",
    "    # Iterar sobre as colunas e plotar os gráficos nos subplots\n",
    "    for i, column in enumerate(cancer_data.columns[2:]):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Contar a quantidade de valores categóricos\n",
    "        count_values = cancer_data[column].value_counts()\n",
    "        count_values.plot(kind='bar', color=['navy', 'red', 'gray'], ax=axes[row, col])\n",
    "\n",
    "        axes[row, col].set_title(f'Contagem de valores em {column}')\n",
    "        axes[row, col].set_xlabel(column)\n",
    "        axes[row, col].set_ylabel('Quantidade')\n",
    "        axes[row, col].set_xticklabels(count_values.index, rotation=0)\n",
    "\n",
    "    # Remover subplots vazios\n",
    "    for i in range(num_features, num_rows * num_cols):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    # Exibir a figura\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def preprocess_and_impute(data):\n",
    "    # Converter '?' para NaN\n",
    "    data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "    # Verificar a porcentagem de dados faltantes\n",
    "    missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "    missing_percentage = missing_percentage[missing_percentage > 0]  # Apenas colunas com dados faltantes\n",
    "    if not missing_percentage.empty:\n",
    "        print(\"Porcentagem de Dados Faltantes por Coluna:\")\n",
    "        print(missing_percentage.sort_values(ascending=False))\n",
    "    else:\n",
    "        print(\"Não há dados faltantes no conjunto de dados.\")\n",
    "\n",
    "    # Converter as colunas para valores numéricos (0 e 1)\n",
    "    data['TARGET_COLUMN'] = data['TARGET_COLUMN'].map({'M': 1, 'B': 0})\n",
    "\n",
    "    # Substituir NAType por None\n",
    "    data = data.where(pd.notna(data), None)\n",
    "\n",
    "    # Extrair colunas de atributos (excluindo a coluna de classe)\n",
    "    attributes = data.drop('TARGET_COLUMN', axis=1)\n",
    "\n",
    "    # Criar o imputador KNN\n",
    "    imputer_knn = KNNImputer(n_neighbors=NUM_K)\n",
    "\n",
    "    # Preencher os valores ausentes nos atributos com o imputador KNN\n",
    "    attributes_imputed = imputer_knn.fit_transform(attributes)\n",
    "\n",
    "    # Criar um novo DataFrame com os valores preenchidos\n",
    "    data_imputed = pd.DataFrame(attributes_imputed, columns=attributes.columns)\n",
    "\n",
    "    # Adicionar a coluna de classe ao novo DataFrame\n",
    "    data_imputed['TARGET_COLUMN'] = data['TARGET_COLUMN']\n",
    "\n",
    "    # Normalizar os dados\n",
    "    scaler = StandardScaler()\n",
    "    data_imputed.iloc[:, :-1] = scaler.fit_transform(data_imputed.iloc[:, :-1])\n",
    "\n",
    "    return data_imputed\n",
    "\n",
    "def train_mlp_model(X, y, num_folds=NUM_FOLDS):\n",
    "    # Pré-processamento e imputação dos dados\n",
    "    processed_data = preprocess_and_impute(pd.concat([X, y], axis=1))\n",
    "\n",
    "    # Não é necessário excluir 'ID' e 'Diagnosis' aqui, pois a função preprocess_and_impute já inclui 'Diagnosis'\n",
    "    X_processed = processed_data.drop(['TARGET_COLUMN'], axis=1)\n",
    "    y_processed = processed_data['TARGET_COLUMN'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "    if NORMALIZATION_FLAG==1:\n",
    "        # Normalizar os dados (Ao ser efetuada essa função, todos os resultados atingem seus valores máximos)\n",
    "        scaler = StandardScaler()\n",
    "        X_processed_scaled = scaler.fit_transform(X_processed)\n",
    "        print(\"\\nOBSERVAÇÃO: Base de Dados DEVIDAMENTE Normalizados\")\n",
    "    else:\n",
    "        print(\"\\nOBSERVAÇÃO: Esses Dados NÃO Estão Normalizados\")\n",
    "\n",
    "    # Inicializar listas para armazenar as métricas de desempenho\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Inicializar listas para armazenar os parâmetros do modelo\n",
    "    model_parameters = []\n",
    "\n",
    "    # Incluir o modelo treinado e seus parâmetros em uma lista\n",
    "    models_and_params = []\n",
    "\n",
    "    # Criar o objeto StratifiedKFold para dividir os dados em folds\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    print(\"\\nAnálise do Treinamento da Rede MLP\")\n",
    "\n",
    "    # Iterar sobre os folds\n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(X, y), 1):\n",
    "\n",
    "        if NORMALIZATION_FLAG==1:\n",
    "            # Dividir os dados em treinamento e teste (quando há Normalização)\n",
    "            X_train, X_test = X_processed_scaled[train_index], X_processed_scaled[test_index]\n",
    "            y_train, y_test = y_processed.iloc[train_index], y_processed.iloc[test_index]\n",
    "        else:\n",
    "            # Dividir os dados em treinamento e teste (quando não há Normalização)\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Criar o modelo MLP\n",
    "        model = MLPClassifier(hidden_layer_sizes=NUM_HIDDEN_LAYERS, max_iter=MAX_ITER, random_state=42)\n",
    "\n",
    "        # Treinar o modelo\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Armazenar os parâmetros do modelo\n",
    "        model_parameters.append(model.get_params())\n",
    "\n",
    "        # Avaliar o desempenho do modelo nos dados de teste\n",
    "        predicted_labels = model.predict(X_test)\n",
    "\n",
    "        # Calcular as métricas de desempenho para o fold atual\n",
    "        accuracy = accuracy_score(y_test, predicted_labels)\n",
    "        precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "        recall = recall_score(y_test, predicted_labels, average='weighted')\n",
    "        f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "        # Armazenar as métricas de desempenho\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Exibir as métricas de desempenho para o fold atual\n",
    "        print(f\"Fold {fold} - Acurácia: {accuracy:.4f}, Precisão: {precision:.4f}, Revocação: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "    # Calcular as médias das métricas de desempenho\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "    # Exibir as médias das métricas de desempenho\n",
    "    print(f\"\\nAcurácia Média (Accuracy): {mean_accuracy:.4f}\")\n",
    "    print(f\"Precisão Média (Precision): {mean_precision:.4f}\")\n",
    "    print(f\"Revocação Média (Recall): {mean_recall:.4f}\")\n",
    "    print(f\"F1-score Média (P*R/(P+R)): {mean_f1:.4f}\")\n",
    "\n",
    "    # Plotar a matriz de confusão\n",
    "    cm = confusion_matrix(y_test, predicted_labels)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['B', 'M'], yticklabels=['B', 'M'])\n",
    "    plt.title(f\"Matriz de Confusão\")\n",
    "    plt.xlabel('Rótulos Previstos')\n",
    "    plt.ylabel('Rótulos Verdadeiros')\n",
    "    plt.show()\n",
    "\n",
    "    if NORMALIZATION_FLAG==1:\n",
    "        #Avaliação do modelo com validação cruzada (quando há Normalização)\n",
    "        model = MLPClassifier(hidden_layer_sizes=NUM_HIDDEN_LAYERS, max_iter=MAX_ITER, random_state=RANDOM_STATE)\n",
    "        cross_val_scores = cross_val_score(model, X_processed_scaled, y_processed, cv=num_folds)\n",
    "        # Exibir as pontuações de validação cruzada\n",
    "        print(f\"\\nPontuações de Acurácia na Validação Cruzada: {cross_val_scores}\")\n",
    "        print(f\"Acurácia Média na Validação Cruzada: {cross_val_scores.mean():.4f}\")\n",
    "        # Treinar o modelo final (quando há Normalização)\n",
    "        model.fit(X_processed_scaled, y_processed)\n",
    "    else:\n",
    "        # Criar o modelo MLP (quando não há Normalização)\n",
    "        model = MLPClassifier(hidden_layer_sizes=NUM_HIDDEN_LAYERS, max_iter=MAX_ITER, random_state=RANDOM_STATE)\n",
    "        # Treinar o modelo (quando não há Normalização)\n",
    "        model.fit(X_train, y_train)  # Removido: drop(['ID', 'Diagnosis'], axis=1)\n",
    "\n",
    "    # Armazenar o modelo treinado e seus parâmetros\n",
    "    models_and_params.append({\n",
    "        'model': model,\n",
    "        'params': model.get_params()\n",
    "    })\n",
    "\n",
    "    return models_and_params\n",
    "\n",
    "def get_mlp_parameters(params):\n",
    "    # Obter os parâmetros específicos do modelo MLP\n",
    "    parameters = []\n",
    "    parameters.append(['hidden_layer_sizes', params['hidden_layer_sizes']])\n",
    "    parameters.append(['activation', params['activation']])\n",
    "    parameters.append(['solver', params['solver']])\n",
    "    parameters.append(['alpha', params['alpha']])\n",
    "    parameters.append(['max_iter', params['max_iter']])\n",
    "    parameters.append(['random_state', params['random_state']])\n",
    "\n",
    "    # Criar um DataFrame com os parâmetros\n",
    "    df_parameters = pd.DataFrame(parameters, columns=['Parâmetro', 'Valor'])\n",
    "\n",
    "    return df_parameters\n",
    "\n",
    "def plot_learning_curve(model, X, y, num_folds=NUM_FOLDS):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=num_folds, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training Score', color='blue')\n",
    "    plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Validation Score', color='navy')\n",
    "    plt.title('Curva de Aprendizado')\n",
    "    plt.xlabel('Número de Exemplos de Treinamento')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def get_mlp_layers_info(model):\n",
    "    # Obter informações sobre todas as camadas ocultas e a camada de saída do modelo MLP\n",
    "    layers_info = []\n",
    "\n",
    "    # Adicionar camada de entrada (atributos)\n",
    "    layers_info.append({\n",
    "        'layer': 0,\n",
    "        'num_neurons': model.coefs_[0].shape[0],  # Número de neurônios na camada de entrada\n",
    "        'bias': None  # Não há viés (bias) na camada de entrada\n",
    "    })\n",
    "\n",
    "    # Adicionar camadas ocultas\n",
    "    for i in range(len(model.coefs_)):\n",
    "        # Número de neurônios na camada oculta i\n",
    "        num_neurons = model.coefs_[i].shape[1]\n",
    "\n",
    "        # Viés (bias) da camada oculta i\n",
    "        bias = model.intercepts_[i]\n",
    "\n",
    "        layers_info.append({\n",
    "            'layer': i + 1,\n",
    "            'num_neurons': num_neurons,\n",
    "            'bias': bias.tolist()  # Convertendo para lista para facilitar a exibição\n",
    "        })\n",
    "\n",
    "    # Adicionar camada de saída\n",
    "    layers_info.append({\n",
    "        'layer': len(model.coefs_) + 1,\n",
    "        'num_neurons': model.coefs_[-1].shape[0],  # Número de neurônios na camada de saída\n",
    "        'bias': model.intercepts_[-1].tolist()  # Viés (bias) na camada de saída\n",
    "    })\n",
    "\n",
    "    return layers_info\n",
    "\n",
    "def plot_weights(model, feature_names):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, coef in enumerate(model.coefs_):\n",
    "        plt.subplot(1, len(model.coefs_), i + 1)\n",
    "        plt.imshow(coef, interpolation='none', cmap='viridis')\n",
    "        plt.title(f'Camada {i+1}')\n",
    "        plt.xticks(range(len(feature_names)), feature_names, rotation=90)\n",
    "        plt.yticks(range(coef.shape[0]))\n",
    "        plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''Inicialização do Código Principal chamando os Blocos de Função Anteriores'''\n",
    "if __name__ == \"__main__\":\n",
    "    cancer_data = download_and_load_data()\n",
    "    display_initial_table(cancer_data)\n",
    "    display_data_summary(cancer_data)\n",
    "    visualize_class_distribution(cancer_data)\n",
    "    #visualize_column_distribution(cancer_data)\n",
    "\n",
    "    # Pré-processamento e imputação dos dados\n",
    "    processed_data = preprocess_and_impute(cancer_data)\n",
    "    X_processed = processed_data.drop(['ID', 'TARGET_COLUMN'], axis=1)\n",
    "    y_processed = processed_data['TARGET_COLUMN']\n",
    "\n",
    "    # Chamar a função e armazenar os parâmetros retornados\n",
    "    model_params_all_folds = train_mlp_model(X_processed, y_processed)\n",
    "\n",
    "    # Salvar o modelo treinado em um arquivo\n",
    "    #import joblib\n",
    "    #joblib.dump(model_params_all_folds, 'mlp_model.joblib')\n",
    "\n",
    "    # Carregar o modelo treinado a partir do arquivo\n",
    "    #loaded_model = joblib.load('mlp_model.joblib')\n",
    "\n",
    "    # Exibir os parâmetros e informações das camadas para todos os folds\n",
    "    for fold, model_params in enumerate(model_params_all_folds, num_folds):\n",
    "        model = model_params['model']\n",
    "        df_parameters = get_mlp_parameters(model_params['params'])\n",
    "        layers_info = get_mlp_layers_info(model)\n",
    "\n",
    "        # Exibir as informações das camadas em uma tabela\n",
    "        df_layers_info = pd.DataFrame(layers_info)\n",
    "        print(f\"\\nParâmetros do Modelo:\\n{df_parameters}\")\n",
    "        print(f\"\\nInformações das Camadas:\\n{df_layers_info}\")\n",
    "        print(\"OBSERVAÇÃO: Lembrando que as camadas ocultas são aquelas removendo a camada de saída e a de entrada\")\n",
    "\n",
    "    # Chamar a função para plotar os pesos\n",
    "    print(\"\\nGráfico de Pesos de cada uma das Camadas Ocultas da rede MLP\")\n",
    "    plot_weights(model, X_processed.columns)\n",
    "\n",
    "    # Exibir curva de aprendizagem dos modelos\n",
    "    print(\"\\nGráfico das Curvas de Aprendizado para Teste e Validação\")\n",
    "    plot_learning_curve(MLPClassifier(hidden_layer_sizes=NUM_HIDDEN_LAYERS, max_iter=MAX_ITER, random_state=RANDOM_STATE),\n",
    "                X_processed, y_processed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSIDERAÇÕES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se todas as métricas, incluindo acurácia, precisão, recall e F1-score, atingiram 100%, isso sugere que o modelo está performando perfeitamente no conjunto de dados específico em que foi treinado e avaliado (mesmo havendo possibilidade disso ser enganoso devido ao OverFitting ou Desbalanceamento de Classes). Entretanto, pelas métricas obtidas, podemos fazer algumas análises:\n",
    "\n",
    "- Acurácia (Accuracy): Todas as previsões feitas pelo modelo estão corretas em relação ao rótulo verdadeiro. A acurácia é a proporção de previsões corretas em relação ao total de previsões.\n",
    "\n",
    "- Precisão (Precision): Todas as instâncias que o modelo previu como positivas (classe 'M') eram realmente positivas. A precisão é a proporção de verdadeiros positivos em relação ao total previsto como positivo.\n",
    "\n",
    "- Revocação (Recall): Todas as instâncias positivas (classe 'M') foram corretamente identificadas pelo modelo. A revocação é a proporção de verdadeiros positivos em relação ao total real de positivos.\n",
    "\n",
    "- F1-Score: A F1-Score é a média harmônica entre precisão e recall. Se ambas forem 100%, a F1-Score também será 100%.\n",
    "\n",
    "- Validação Cruzada: Se o modelo atingiu 100% em todas as métricas em vários folds durante a validação cruzada, isso é mais promissor e sugere uma boa generalização.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código anterior, no módulo de função do treinamento da rede MLP (train_mlp_model), para deixar explicitada a modificação dos parâmetros com a normalização, o treinamento da rede está escrito com indicação de quando a Normalização é acionada e quando ela não é acionada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
